{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line assigns a variable to the filepath used to read the `.md` file.\n",
    "\n",
    "The final pair of lines assigns variables to a corresponding pair of lists. These lists will be useful for comparing against the resume.md file to automatically, without a human reading the file at all, determine whether the resume contains relevant experience/qualification.\n",
    "\n",
    "These variables are in ALL CAPS because they are assigned to \"CONSTANTS\", rendering them unchangeable. (i.e. `.append`, `.pop`, and similar attributes would not affect these variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`def load_file(filepath):` defines `load_file` as a function that may be used in a later cell to access the .csv file (by way of variable `resume_path`).\n",
    "The pursuant lines do as follows:\n",
    "     `resume_contents = resume_file_handler.read()`  reads text appearing in `resume.md` and converts it into a single readable variable in Python\n",
    "     `resume_contents = resume_contents.lower()` converts any uppercase letters to lowercase\n",
    "     `resume_tokens = resume_contents.split()` converts the single-item string extracted from the `resumed.md` file and to a list of one-word items (`resume_tokens`)\n",
    "     `return resume_tokens` renders the list `resume_tokens` as a readable variable that can be fully read when the coder is read to use the newly defined `load_file` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates and assigns a list containing all of the words, separated as individual items, in the `resume.md` file. The cell doesn't output anything, but `word_list` will be the variable we use to evaluate the resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first line:\n",
    "The set is created such that, at a later time, items/lists can be appended to it. At that time, outputting the set will neatly sort the values within, eliminating duplicates and arranging the items alphabetically.\n",
    "\n",
    "In the second and third lines:\n",
    "A `forloop` is run that adds all items within `word_list` to the newly defined set (`resume`).\n",
    "\n",
    "The punctuation set is created (by means of `set(string.puntuation)`) so that it may be subtracted from the set. That is to say, in the line `resume = resume - punctuation` all values appearing in punctuation will be removed from the set. This leaves the set devoid of punctuation, which is irrelevant for the purposes of evaluating keywords (like the ones in variables ` REQUIRED_SKILLS` and `DESIRED_SKILLS`)\n",
    "\n",
    "'\\n' in a printed string is the equivalent of the \"Enter\" key in a standard word processor: it prints string(s) following it on a new line.\n",
    "\n",
    "The final line prints the newly filled and filtered set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'tables', 'python', 'statistics,', 'using', '##', 'visualizations', 'css,', 'open-source', 'working', 'designing', 'media', 'r,', 'hadoop,', 'html,', '*', 'from', 'excel,', 'experience', 'tableau,', 'javascript,', 'analyze', 'graduate', 'mining', 'business', 'statistics', 'mining,', 'mongodb', 'social', 'and', 'in', 'pivot', 'learning', 'data', 'python,', 'd3', 'camp', 'excel.', 'contributing', 'visualization', 'the', 'frank', 'leaflet.js', 'writing', 'big', '#', 'learning,', 'skills', 'advanced', 'machine', 'hadoop', 'basic', 'html/css,', 'front-end', 'git/github', 'interests', 'bootstrap,', 'to', 'tableau', 'with', 'api', 'stein', 'sql,', 'developing', 'files', 'performing', 'creating', 'scripts', 'microsoft', 'apis.', 'software', 'boot', 'modeling', 'forecasting', 'aws', 'pandas', 'd3,', 'n.', 'education', 'sets', 'databases', 'interactions,', 'intelligence', 'vba', 'algorithms', 'analytics', 'web', 'apps', 'mysql', 'cloud'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'tables', 'python', 'statistics,', 'using', '##', 'visualizations', 'css,', 'open-source', 'working', 'designing', 'media', 'r,', 'hadoop,', 'html,', 'from', 'excel,', 'experience', 'tableau,', 'javascript,', 'analyze', 'graduate', 'mining', 'business', 'statistics', 'mongodb', 'mining,', 'social', 'and', 'in', 'pivot', 'learning', 'data', 'python,', 'd3', 'camp', 'excel.', 'contributing', 'visualization', 'the', 'frank', 'leaflet.js', 'writing', 'big', 'learning,', 'skills', 'advanced', 'machine', 'hadoop', 'basic', 'html/css,', 'front-end', 'git/github', 'interests', 'bootstrap,', 'to', 'tableau', 'with', 'api', 'stein', 'sql,', 'developing', 'files', 'performing', 'creating', 'scripts', 'microsoft', 'apis.', 'software', 'boot', 'modeling', 'forecasting', 'aws', 'pandas', 'd3,', 'n.', 'education', 'sets', 'databases', 'interactions,', 'intelligence', 'vba', 'algorithms', 'analytics', 'web', 'apps', 'mysql', 'cloud'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The character cleaning removes an errant punctuation value that was missed when running the `set(string.punctuation)` in the previous cell: specifically \"##\".\n",
    "\n",
    "While the stop_words list is comprehensive enough to remove most obstructive values, I might also add \"frank\", \"n\", \"stein\", \"from\", and \"the\".\n",
    "\n",
    "The logic employed by the `word_list` list comprehension is essentially:\n",
    "-for each `x` in `word_list`, where `x` = a single item in the list\n",
    "      if `x` does not appear in `stop_words`\n",
    "           then output `x`\n",
    "      else `x` does appear in `stop_words`\n",
    "           do nothing and skip to next `x`\n",
    "This yields a list of words from `word_list` containing none of the values in `punctuation`, `stop_words`, or as filtered in the `char` filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'mysql', 'python', 'statistics'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n.', 'stein', '##', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '##', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel.', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis.', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'front-end', 'web', 'visualizations', 'using', 'html,', 'css,', 'bootstrap,', 'd3,', 'and', 'leaflet.js', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '##', 'skills', 'microsoft', 'excel,', 'python,', 'javascript,', 'html/css,', 'api', 'interactions,', 'social', 'media', 'mining,', 'sql,', 'hadoop,', 'tableau,', 'advanced', 'statistics,', 'machine', 'learning,', 'r,', 'git/github', '##', 'interests', 'contributing', 'to', 'open-source', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html,', 'css,', 'javascript,', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`word_count` is initialized/converted to a dictionary by way of the `{}.fromkeys()` attribute. This creates a dictionary of all the words in word list with dictionary defintions of `{[\"word\":0], [\"word\":0], etc...}`\n",
    "\n",
    "The word key in the `word_count` dictionary is referenced by way of `word_count[word]`, where `word` equals each incremental value appearing in the `word_list` forloop. As the forloop runs, `word_count[word] += 1` increases the value of `x` in `[\"word\":x]`.\n",
    "\n",
    "`collections.counter` effectively combines the initialization in the first line with the forloop in the 2nd/3rd lines, creating a dictionary of words appearing in `word_list` paired with an integer representing their number of iterations within `word_list`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Counter\n",
      "Counter({'data': 7, '': 4, 'python': 4, 'analytics': 3, 'visualization': 2, 'scripts': 2, 'excel': 2, 'statistics': 2, 'social': 2, 'media': 2, 'mining': 2, 'web': 2, 'html': 2, 'css': 2, 'd3': 2, 'the': 2, 'tableau': 2, 'software': 2, 'big': 2, 'hadoop': 2, 'machine': 2, 'learning': 2, 'javascript': 2, 'frank': 1, 'n': 1, 'stein': 1, 'education': 1, 'boot': 1, 'camp': 1, 'graduate': 1, 'experience': 1, 'creating': 1, 'pivot': 1, 'tables': 1, 'vba': 1, 'modeling': 1, 'forecasting': 1, 'basic': 1, 'writing': 1, 'analyze': 1, 'sets': 1, 'from': 1, 'files': 1, 'apis': 1, 'mysql': 1, 'mongodb': 1, 'databases': 1, 'developing': 1, 'frontend': 1, 'visualizations': 1, 'bootstrap': 1, 'leafletjs': 1, 'business': 1, 'intelligence': 1, 'performing': 1, 'algorithms': 1, 'skills': 1, 'microsoft': 1, 'htmlcss': 1, 'api': 1, 'interactions': 1, 'sql': 1, 'advanced': 1, 'r': 1, 'gitgithub': 1, 'interests': 1, 'contributing': 1, 'opensource': 1, 'pandas': 1, 'designing': 1, 'apps': 1, 'cloud': 1, 'aws': 1})\n",
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "print(\"Word Counter\")\n",
    "print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line creates an empty list at variable `sorted_words`.\n",
    "\n",
    "The second line begins a forloop following these operations\n",
    "     `word_count` outputs each value of `word` in `word_count`\n",
    "     `key=word_count.get` outputs the corresponding integer produced in the above cell\n",
    "     `reverse=True` arranges the integers from highest to lowest.\n",
    "     `[:10]` limits the output to 10 word-integer pairings.\n",
    "\n",
    "The third line prints the output with a couple unique specifications:\n",
    "     `f'` strings allow the output to contain both strings and non-string variables.\n",
    "     The `:20` in `{word:20}` formats the output such that \"Count\" and all string(s) following it will be spaced a uniform distance to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token:                      Count: 4\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
